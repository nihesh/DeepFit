# Author : Nihesh Anderson 
# Date 	 : 18 Feb, 2020
# File	 : model.py

import torch
import torch.nn as nn
from src.constants import EPS
import torch.nn.functional as F
import models.pointnet as pointnet
import models.autoencoder as autoencoder
import models.compressor as compressor

class DeepFit(nn.Module):

	"""
	A deep neural network architecture that predicts the distribution over points of being an inlier, given the state and feature vector
	"""

	def __init__(self, feature_dim, output_hyp_cnt, ptnet_scale, num_correspondences):

		"""
		Input:
			Feature dim 		- The number of features in the feature vector generated by density/residual estimate (Usually the number of hypothesis sampled)
			output_hyp_cnt 		- The number of hypothesis sampled from the distribution computed by DeepFit (The best model is picked)
			ptnet_scale 		- The factor by which point net weights should be reduced
			num_correspondences - Number of point correspondences [This has to be removed in the future]
		"""

		super(DeepFit, self).__init__()

		self.pointnet = pointnet.PointNetFeatureGenerator(feature_dim, scale = ptnet_scale).cuda()
		self.state_transformer = autoencoder.AutoEncoder(num_correspondences, 50)
		
		self.compressor = compressor.Compressor(int(64 / ptnet_scale) + int(64 / ptnet_scale))
		
		# HACK
		# self.compressor = compressor.Compressor((64 // ptnet_scale))

	def forward(self, feature, state):

		"""
		Forward propagation step for our architecture
		Input:
			feature - [batch_size x num_correspondences x dim (num_hypothesis used in dgsac)] density/residual features returned by the dataset class 
			state 	- [batch_size x num_correspondences] 1D encoding of whether the ith sample has been considered as an inlier for hypothesis generated so far
		Output:
			A set of t hypothesis 
		"""

		batch_size = feature.shape[0]
		num_correspondences = feature.shape[1]
		dim = feature.shape[2]

		# Compute state mask
		state_mask = self.state_transformer(state)

		# HACK - Change this
		state_mask = state
		
		# Scale the features using mask
		masked_feature = feature * (1 - state_mask).view(batch_size, num_correspondences, 1)

		# Pointnet uses num_correspondences in the last dimension - different from our convention
		masked_feature = masked_feature.transpose(1, 2)

		# Forward pass through pointnet
		ptnet_embed = self.pointnet(masked_feature)
		# Change embedding back to our convention
		ptnet_embed = ptnet_embed.permute(0, 2, 1)

		flattened_ptnet_embed = ptnet_embed.contiguous().view(batch_size * num_correspondences, ptnet_embed.shape[2])

		# Compute distribution using the scaled embedding vector
		distribution = self.compressor(flattened_ptnet_embed)
		distribution = distribution.view(batch_size, num_correspondences)

		return ptnet_embed, distribution